{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df  =  pd.read_parquet(\"data/validate_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1082224, 101)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection ## select every feature except 0-4 \n",
    "feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "#select target values\n",
    "target_cols = [\"responder_6\"]\n",
    "\n",
    "# select the weight values\n",
    "weight_cols = [\"weight\"]\n",
    "\n",
    "# the chunk requir maximum memory\n",
    "\n",
    "X_val =     val_df[feature_cols]\n",
    "y_val =     val_df[target_cols]\n",
    "w_val =     val_df[weight_cols]\n",
    "\n",
    "del  val_df # free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            # layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))  # 输出层\n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        y = y.view(-1)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  #\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        y = y.view(-1)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "    #     y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #     if self.trainer.sanity_checking:\n",
    "    #         prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #     else:\n",
    "    #         prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #         weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #         # Ensure the shapes match by specifying the axis\n",
    "    #         val_r_square = r2_val(y, prob, weights, axis=0)\n",
    "    #         self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "    #     self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the model's state dictionary to the specified path.\"\"\"\n",
    "        torch.save(self.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): BatchNorm1d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): Linear(in_features=88, out_features=512, bias=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): SiLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): SiLU()\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (11): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmodel =  MyModel.load_from_checkpoint(\"lightning_logs/version_24/checkpoints/models/nn.model.ckpt\")\n",
    "nnmodel.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015774965286254883"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    prednn = nnmodel(torch.FloatTensor(X_val.values).to(\"cuda\"))\n",
    "prednn = prednn.cpu().detach().numpy()\n",
    "r2_score(y_val, prednn, sample_weight= w_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>responder_0_lag_1</th>\n",
       "      <th>responder_1_lag_1</th>\n",
       "      <th>responder_2_lag_1</th>\n",
       "      <th>responder_3_lag_1</th>\n",
       "      <th>responder_4_lag_1</th>\n",
       "      <th>responder_5_lag_1</th>\n",
       "      <th>responder_6_lag_1</th>\n",
       "      <th>responder_7_lag_1</th>\n",
       "      <th>responder_8_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.442215</td>\n",
       "      <td>-0.322407</td>\n",
       "      <td>0.143594</td>\n",
       "      <td>-0.926890</td>\n",
       "      <td>-0.782236</td>\n",
       "      <td>-0.036595</td>\n",
       "      <td>-1.305746</td>\n",
       "      <td>-0.795677</td>\n",
       "      <td>-0.143724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.651829</td>\n",
       "      <td>-1.707840</td>\n",
       "      <td>-0.893942</td>\n",
       "      <td>-1.065488</td>\n",
       "      <td>-1.871338</td>\n",
       "      <td>-0.615652</td>\n",
       "      <td>-1.162801</td>\n",
       "      <td>-1.205924</td>\n",
       "      <td>-1.245934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.656373</td>\n",
       "      <td>-0.264575</td>\n",
       "      <td>-0.892879</td>\n",
       "      <td>-1.511886</td>\n",
       "      <td>-1.033480</td>\n",
       "      <td>-0.378265</td>\n",
       "      <td>-1.574290</td>\n",
       "      <td>-1.863071</td>\n",
       "      <td>-0.027343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.188186</td>\n",
       "      <td>-0.190970</td>\n",
       "      <td>-0.701490</td>\n",
       "      <td>0.098453</td>\n",
       "      <td>-1.015506</td>\n",
       "      <td>-0.054984</td>\n",
       "      <td>0.329152</td>\n",
       "      <td>-0.965471</td>\n",
       "      <td>0.576635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.257462</td>\n",
       "      <td>-0.471325</td>\n",
       "      <td>-0.297420</td>\n",
       "      <td>0.074018</td>\n",
       "      <td>-0.324194</td>\n",
       "      <td>-0.597093</td>\n",
       "      <td>0.219856</td>\n",
       "      <td>-0.276356</td>\n",
       "      <td>-0.904790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>-0.020169</td>\n",
       "      <td>0.640348</td>\n",
       "      <td>-0.948373</td>\n",
       "      <td>-0.374251</td>\n",
       "      <td>-0.240350</td>\n",
       "      <td>-0.913801</td>\n",
       "      <td>-0.548867</td>\n",
       "      <td>-1.283726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.419646</td>\n",
       "      <td>-0.181228</td>\n",
       "      <td>-0.194079</td>\n",
       "      <td>0.667993</td>\n",
       "      <td>0.936857</td>\n",
       "      <td>0.517728</td>\n",
       "      <td>0.896325</td>\n",
       "      <td>1.068884</td>\n",
       "      <td>1.579290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.114118</td>\n",
       "      <td>-0.198511</td>\n",
       "      <td>-0.200027</td>\n",
       "      <td>-0.410021</td>\n",
       "      <td>-0.135167</td>\n",
       "      <td>-0.182887</td>\n",
       "      <td>-0.492168</td>\n",
       "      <td>-0.142915</td>\n",
       "      <td>-0.202081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.374147</td>\n",
       "      <td>0.092127</td>\n",
       "      <td>0.294723</td>\n",
       "      <td>0.402989</td>\n",
       "      <td>2.060188</td>\n",
       "      <td>-0.225042</td>\n",
       "      <td>0.956460</td>\n",
       "      <td>2.185598</td>\n",
       "      <td>-0.435856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.529529</td>\n",
       "      <td>0.040104</td>\n",
       "      <td>-0.333090</td>\n",
       "      <td>-0.959040</td>\n",
       "      <td>-1.318411</td>\n",
       "      <td>-0.774299</td>\n",
       "      <td>-0.716492</td>\n",
       "      <td>-1.471419</td>\n",
       "      <td>-1.107083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.709064</td>\n",
       "      <td>-0.137431</td>\n",
       "      <td>-0.475960</td>\n",
       "      <td>-0.506644</td>\n",
       "      <td>-0.297788</td>\n",
       "      <td>-0.530738</td>\n",
       "      <td>-0.263427</td>\n",
       "      <td>-0.169489</td>\n",
       "      <td>-0.410877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.182779</td>\n",
       "      <td>-0.262493</td>\n",
       "      <td>-0.349921</td>\n",
       "      <td>-0.725857</td>\n",
       "      <td>-0.469289</td>\n",
       "      <td>-1.125309</td>\n",
       "      <td>-0.832106</td>\n",
       "      <td>-0.240194</td>\n",
       "      <td>-0.760374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.409564</td>\n",
       "      <td>-0.210898</td>\n",
       "      <td>-0.097313</td>\n",
       "      <td>0.420984</td>\n",
       "      <td>-1.611198</td>\n",
       "      <td>1.065879</td>\n",
       "      <td>0.798224</td>\n",
       "      <td>-3.035606</td>\n",
       "      <td>1.810822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.254306</td>\n",
       "      <td>0.114433</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>-0.685130</td>\n",
       "      <td>-0.384532</td>\n",
       "      <td>-0.765541</td>\n",
       "      <td>-1.385921</td>\n",
       "      <td>-0.441037</td>\n",
       "      <td>-1.359048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.464961</td>\n",
       "      <td>0.077041</td>\n",
       "      <td>0.601805</td>\n",
       "      <td>-0.178444</td>\n",
       "      <td>1.127965</td>\n",
       "      <td>-0.445524</td>\n",
       "      <td>-0.507432</td>\n",
       "      <td>0.985169</td>\n",
       "      <td>-1.497043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.059957</td>\n",
       "      <td>0.173762</td>\n",
       "      <td>-0.248479</td>\n",
       "      <td>-0.187606</td>\n",
       "      <td>0.539572</td>\n",
       "      <td>0.244086</td>\n",
       "      <td>-0.256192</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.636512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.138667</td>\n",
       "      <td>0.062221</td>\n",
       "      <td>-0.140365</td>\n",
       "      <td>-2.740061</td>\n",
       "      <td>-1.360370</td>\n",
       "      <td>-1.297678</td>\n",
       "      <td>-2.992689</td>\n",
       "      <td>-2.387136</td>\n",
       "      <td>-1.834790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.235209</td>\n",
       "      <td>-0.201598</td>\n",
       "      <td>0.406477</td>\n",
       "      <td>4.062799</td>\n",
       "      <td>1.399957</td>\n",
       "      <td>2.418881</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.615073</td>\n",
       "      <td>3.689315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>-1.760321</td>\n",
       "      <td>-0.488708</td>\n",
       "      <td>-0.883805</td>\n",
       "      <td>0.771329</td>\n",
       "      <td>1.164359</td>\n",
       "      <td>2.030865</td>\n",
       "      <td>2.570583</td>\n",
       "      <td>2.326662</td>\n",
       "      <td>2.364794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.120426</td>\n",
       "      <td>-0.257001</td>\n",
       "      <td>0.461233</td>\n",
       "      <td>0.334276</td>\n",
       "      <td>-0.430230</td>\n",
       "      <td>-0.053538</td>\n",
       "      <td>0.386924</td>\n",
       "      <td>-0.633187</td>\n",
       "      <td>-0.465996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.100019</td>\n",
       "      <td>-0.064951</td>\n",
       "      <td>0.103129</td>\n",
       "      <td>0.194796</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.019647</td>\n",
       "      <td>0.360535</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.118341</td>\n",
       "      <td>-0.156263</td>\n",
       "      <td>-0.315895</td>\n",
       "      <td>-1.117113</td>\n",
       "      <td>-0.318234</td>\n",
       "      <td>-1.938428</td>\n",
       "      <td>-1.851255</td>\n",
       "      <td>-0.355483</td>\n",
       "      <td>-2.953523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.077620</td>\n",
       "      <td>-0.095140</td>\n",
       "      <td>-0.195245</td>\n",
       "      <td>2.259837</td>\n",
       "      <td>-0.049306</td>\n",
       "      <td>0.815069</td>\n",
       "      <td>2.036146</td>\n",
       "      <td>0.032317</td>\n",
       "      <td>1.591067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.049998</td>\n",
       "      <td>-0.024269</td>\n",
       "      <td>0.399543</td>\n",
       "      <td>1.664860</td>\n",
       "      <td>1.774516</td>\n",
       "      <td>0.849245</td>\n",
       "      <td>2.734162</td>\n",
       "      <td>2.179242</td>\n",
       "      <td>2.438320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.053630</td>\n",
       "      <td>0.338161</td>\n",
       "      <td>0.828120</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>0.594190</td>\n",
       "      <td>-2.695299</td>\n",
       "      <td>0.086643</td>\n",
       "      <td>0.464238</td>\n",
       "      <td>-5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.859229</td>\n",
       "      <td>-0.752454</td>\n",
       "      <td>0.372965</td>\n",
       "      <td>1.137440</td>\n",
       "      <td>-0.969744</td>\n",
       "      <td>0.149047</td>\n",
       "      <td>0.522117</td>\n",
       "      <td>-0.690022</td>\n",
       "      <td>-0.084661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.727778</td>\n",
       "      <td>-0.085832</td>\n",
       "      <td>-0.500547</td>\n",
       "      <td>0.080261</td>\n",
       "      <td>-0.168391</td>\n",
       "      <td>-0.017894</td>\n",
       "      <td>0.453380</td>\n",
       "      <td>-0.151904</td>\n",
       "      <td>0.455708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.947047</td>\n",
       "      <td>0.345270</td>\n",
       "      <td>-0.416790</td>\n",
       "      <td>0.068557</td>\n",
       "      <td>2.012803</td>\n",
       "      <td>1.190820</td>\n",
       "      <td>0.641240</td>\n",
       "      <td>2.143041</td>\n",
       "      <td>2.033262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.185609</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.928451</td>\n",
       "      <td>0.699763</td>\n",
       "      <td>0.094604</td>\n",
       "      <td>-0.093131</td>\n",
       "      <td>0.815095</td>\n",
       "      <td>0.101383</td>\n",
       "      <td>-0.993829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.410091</td>\n",
       "      <td>0.073472</td>\n",
       "      <td>0.327349</td>\n",
       "      <td>1.020221</td>\n",
       "      <td>-0.262787</td>\n",
       "      <td>0.182656</td>\n",
       "      <td>0.794698</td>\n",
       "      <td>-0.455156</td>\n",
       "      <td>0.103020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>-0.165723</td>\n",
       "      <td>0.038975</td>\n",
       "      <td>-0.088357</td>\n",
       "      <td>-0.745973</td>\n",
       "      <td>-0.318136</td>\n",
       "      <td>-0.699026</td>\n",
       "      <td>-1.051536</td>\n",
       "      <td>-0.334043</td>\n",
       "      <td>-1.380436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.434564</td>\n",
       "      <td>-2.683184</td>\n",
       "      <td>-0.439510</td>\n",
       "      <td>2.700525</td>\n",
       "      <td>2.373121</td>\n",
       "      <td>0.748074</td>\n",
       "      <td>2.698507</td>\n",
       "      <td>3.004424</td>\n",
       "      <td>1.457855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.319112</td>\n",
       "      <td>-0.359562</td>\n",
       "      <td>-1.037934</td>\n",
       "      <td>1.451325</td>\n",
       "      <td>-1.596154</td>\n",
       "      <td>-0.922532</td>\n",
       "      <td>1.574045</td>\n",
       "      <td>-3.389474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.322945</td>\n",
       "      <td>-0.100357</td>\n",
       "      <td>0.044535</td>\n",
       "      <td>-0.853970</td>\n",
       "      <td>-1.932011</td>\n",
       "      <td>-1.108600</td>\n",
       "      <td>-1.377528</td>\n",
       "      <td>-2.624511</td>\n",
       "      <td>-0.798179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.185392</td>\n",
       "      <td>-0.187891</td>\n",
       "      <td>-0.206658</td>\n",
       "      <td>-0.634903</td>\n",
       "      <td>-0.643175</td>\n",
       "      <td>-0.443875</td>\n",
       "      <td>-0.556474</td>\n",
       "      <td>-1.122211</td>\n",
       "      <td>-0.884185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.308923</td>\n",
       "      <td>-0.434147</td>\n",
       "      <td>-1.354941</td>\n",
       "      <td>0.300540</td>\n",
       "      <td>-0.830827</td>\n",
       "      <td>0.424937</td>\n",
       "      <td>0.518839</td>\n",
       "      <td>-0.687369</td>\n",
       "      <td>1.440577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>-0.074661</td>\n",
       "      <td>-0.261698</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>-2.600390</td>\n",
       "      <td>-1.146709</td>\n",
       "      <td>-1.601274</td>\n",
       "      <td>-3.216254</td>\n",
       "      <td>-1.249338</td>\n",
       "      <td>-2.868875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.658366</td>\n",
       "      <td>-0.282258</td>\n",
       "      <td>-0.438998</td>\n",
       "      <td>-0.709998</td>\n",
       "      <td>-1.143526</td>\n",
       "      <td>-1.562932</td>\n",
       "      <td>-0.506418</td>\n",
       "      <td>-1.355508</td>\n",
       "      <td>-2.630985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.572666</td>\n",
       "      <td>0.066861</td>\n",
       "      <td>-0.552490</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.535348</td>\n",
       "      <td>-0.501347</td>\n",
       "      <td>-0.169114</td>\n",
       "      <td>0.457801</td>\n",
       "      <td>-0.136777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_id  time_id  symbol_id  responder_0_lag_1  responder_1_lag_1  \\\n",
       "0         0        0          0          -0.442215          -0.322407   \n",
       "1         0        0          1          -0.651829          -1.707840   \n",
       "2         0        0          2          -0.656373          -0.264575   \n",
       "3         0        0          3          -0.188186          -0.190970   \n",
       "4         0        0          4          -0.257462          -0.471325   \n",
       "5         0        0          5           0.027579          -0.020169   \n",
       "6         0        0          6          -0.419646          -0.181228   \n",
       "7         0        0          7          -0.114118          -0.198511   \n",
       "8         0        0          8          -0.374147           0.092127   \n",
       "9         0        0          9          -0.529529           0.040104   \n",
       "10        0        0         10          -0.709064          -0.137431   \n",
       "11        0        0         11          -0.182779          -0.262493   \n",
       "12        0        0         12          -0.409564          -0.210898   \n",
       "13        0        0         13           0.254306           0.114433   \n",
       "14        0        0         14           0.464961           0.077041   \n",
       "15        0        0         15           0.059957           0.173762   \n",
       "16        0        0         16           0.138667           0.062221   \n",
       "17        0        0         17          -0.235209          -0.201598   \n",
       "18        0        0         18          -1.760321          -0.488708   \n",
       "19        0        0         19          -0.120426          -0.257001   \n",
       "20        0        0         20           0.100019          -0.064951   \n",
       "21        0        0         21          -0.118341          -0.156263   \n",
       "22        0        0         22           0.077620          -0.095140   \n",
       "23        0        0         23           0.049998          -0.024269   \n",
       "24        0        0         24           0.053630           0.338161   \n",
       "25        0        0         25           0.859229          -0.752454   \n",
       "26        0        0         26          -0.727778          -0.085832   \n",
       "27        0        0         27          -0.947047           0.345270   \n",
       "28        0        0         28           0.185609           0.019040   \n",
       "29        0        0         29           0.410091           0.073472   \n",
       "30        0        0         30          -0.165723           0.038975   \n",
       "31        0        0         31          -0.434564          -2.683184   \n",
       "32        0        0         32          -0.221083           0.319112   \n",
       "33        0        0         33          -0.322945          -0.100357   \n",
       "34        0        0         34          -0.185392          -0.187891   \n",
       "35        0        0         35          -0.308923          -0.434147   \n",
       "36        0        0         36          -0.074661          -0.261698   \n",
       "37        0        0         37          -0.658366          -0.282258   \n",
       "38        0        0         38           0.572666           0.066861   \n",
       "\n",
       "    responder_2_lag_1  responder_3_lag_1  responder_4_lag_1  \\\n",
       "0            0.143594          -0.926890          -0.782236   \n",
       "1           -0.893942          -1.065488          -1.871338   \n",
       "2           -0.892879          -1.511886          -1.033480   \n",
       "3           -0.701490           0.098453          -1.015506   \n",
       "4           -0.297420           0.074018          -0.324194   \n",
       "5            0.640348          -0.948373          -0.374251   \n",
       "6           -0.194079           0.667993           0.936857   \n",
       "7           -0.200027          -0.410021          -0.135167   \n",
       "8            0.294723           0.402989           2.060188   \n",
       "9           -0.333090          -0.959040          -1.318411   \n",
       "10          -0.475960          -0.506644          -0.297788   \n",
       "11          -0.349921          -0.725857          -0.469289   \n",
       "12          -0.097313           0.420984          -1.611198   \n",
       "13           0.064752          -0.685130          -0.384532   \n",
       "14           0.601805          -0.178444           1.127965   \n",
       "15          -0.248479          -0.187606           0.539572   \n",
       "16          -0.140365          -2.740061          -1.360370   \n",
       "17           0.406477           4.062799           1.399957   \n",
       "18          -0.883805           0.771329           1.164359   \n",
       "19           0.461233           0.334276          -0.430230   \n",
       "20           0.103129           0.194796           5.000000   \n",
       "21          -0.315895          -1.117113          -0.318234   \n",
       "22          -0.195245           2.259837          -0.049306   \n",
       "23           0.399543           1.664860           1.774516   \n",
       "24           0.828120           0.061310           0.594190   \n",
       "25           0.372965           1.137440          -0.969744   \n",
       "26          -0.500547           0.080261          -0.168391   \n",
       "27          -0.416790           0.068557           2.012803   \n",
       "28           0.928451           0.699763           0.094604   \n",
       "29           0.327349           1.020221          -0.262787   \n",
       "30          -0.088357          -0.745973          -0.318136   \n",
       "31          -0.439510           2.700525           2.373121   \n",
       "32          -0.359562          -1.037934           1.451325   \n",
       "33           0.044535          -0.853970          -1.932011   \n",
       "34          -0.206658          -0.634903          -0.643175   \n",
       "35          -1.354941           0.300540          -0.830827   \n",
       "36          -0.007051          -2.600390          -1.146709   \n",
       "37          -0.438998          -0.709998          -1.143526   \n",
       "38          -0.552490           0.107840           0.535348   \n",
       "\n",
       "    responder_5_lag_1  responder_6_lag_1  responder_7_lag_1  responder_8_lag_1  \n",
       "0           -0.036595          -1.305746          -0.795677          -0.143724  \n",
       "1           -0.615652          -1.162801          -1.205924          -1.245934  \n",
       "2           -0.378265          -1.574290          -1.863071          -0.027343  \n",
       "3           -0.054984           0.329152          -0.965471           0.576635  \n",
       "4           -0.597093           0.219856          -0.276356          -0.904790  \n",
       "5           -0.240350          -0.913801          -0.548867          -1.283726  \n",
       "6            0.517728           0.896325           1.068884           1.579290  \n",
       "7           -0.182887          -0.492168          -0.142915          -0.202081  \n",
       "8           -0.225042           0.956460           2.185598          -0.435856  \n",
       "9           -0.774299          -0.716492          -1.471419          -1.107083  \n",
       "10          -0.530738          -0.263427          -0.169489          -0.410877  \n",
       "11          -1.125309          -0.832106          -0.240194          -0.760374  \n",
       "12           1.065879           0.798224          -3.035606           1.810822  \n",
       "13          -0.765541          -1.385921          -0.441037          -1.359048  \n",
       "14          -0.445524          -0.507432           0.985169          -1.497043  \n",
       "15           0.244086          -0.256192           0.974333           0.636512  \n",
       "16          -1.297678          -2.992689          -2.387136          -1.834790  \n",
       "17           2.418881           5.000000           1.615073           3.689315  \n",
       "18           2.030865           2.570583           2.326662           2.364794  \n",
       "19          -0.053538           0.386924          -0.633187          -0.465996  \n",
       "20           0.019647           0.360535           5.000000           0.000687  \n",
       "21          -1.938428          -1.851255          -0.355483          -2.953523  \n",
       "22           0.815069           2.036146           0.032317           1.591067  \n",
       "23           0.849245           2.734162           2.179242           2.438320  \n",
       "24          -2.695299           0.086643           0.464238          -5.000000  \n",
       "25           0.149047           0.522117          -0.690022          -0.084661  \n",
       "26          -0.017894           0.453380          -0.151904           0.455708  \n",
       "27           1.190820           0.641240           2.143041           2.033262  \n",
       "28          -0.093131           0.815095           0.101383          -0.993829  \n",
       "29           0.182656           0.794698          -0.455156           0.103020  \n",
       "30          -0.699026          -1.051536          -0.334043          -1.380436  \n",
       "31           0.748074           2.698507           3.004424           1.457855  \n",
       "32          -1.596154          -0.922532           1.574045          -3.389474  \n",
       "33          -1.108600          -1.377528          -2.624511          -0.798179  \n",
       "34          -0.443875          -0.556474          -1.122211          -0.884185  \n",
       "35           0.424937           0.518839          -0.687369           1.440577  \n",
       "36          -1.601274          -3.216254          -1.249338          -2.868875  \n",
       "37          -1.562932          -0.506418          -1.355508          -2.630985  \n",
       "38          -0.501347          -0.169114           0.457801          -0.136777  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"data/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
