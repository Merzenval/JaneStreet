{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df =  pd.read_parquet(\"data/validate_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "#select target values\n",
    "target_cols = [\"responder_6\"]\n",
    "\n",
    "# select the weight values\n",
    "weight_cols = [\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df[feature_cols]\n",
    "y_val = val_df[target_cols]\n",
    "w_val = val_df[weight_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.date_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            # layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))  # 输出层\n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        y = y.view(-1)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  #\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        y = y.view(-1)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    # def on_validation_epoch_end(self):\n",
    "    #     \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "    #     y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #     if self.trainer.sanity_checking:\n",
    "    #         prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #     else:\n",
    "    #         prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #         weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "    #         # Ensure the shapes match by specifying the axis\n",
    "    #         val_r_square = r2_val(y, prob, weights, axis=0)\n",
    "    #         self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "    #     self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # def on_train_epoch_end(self):\n",
    "    #     if self.trainer.sanity_checking:\n",
    "    #         return\n",
    "    #     epoch = self.trainer.current_epoch\n",
    "    #     metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "    #     formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "    #     print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "\n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the model's state dictionary to the specified path.\"\"\"\n",
    "        torch.save(self.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "def cv(pred, n_folds = 10):    \n",
    "    batch_size = len(y_val)//n_folds \n",
    "    r2 = []  \n",
    "    for i in range(0, len(X_val), batch_size):\n",
    "        if i == batch_size*10: return r2\n",
    "        pred_batch = pred[i:i+batch_size]\n",
    "        y_batch = y_val[i:i+batch_size]\n",
    "        w_batch = w_val[i:i+batch_size]\n",
    "        r2.append(r2_score(y_batch, pred_batch, sample_weight= w_batch))\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): Sequential(\n",
       "    (0): BatchNorm1d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.1, inplace=False)\n",
       "    (2): Linear(in_features=90, out_features=512, bias=True)\n",
       "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): SiLU()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): SiLU()\n",
       "    (9): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (10): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (11): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i= 0 \n",
    "# model  = MyModel.load_from_checkpoint(f\"lightning_logs/version_{i+25}/checkpoints/models/nn__fold{i}.model.ckpt\")\n",
    "model  = MyModel.load_from_checkpoint(f\"lightning_logs/version_{32}/checkpoints/models/nn.model.ckpt\")\n",
    "model= model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_vote_model  =  joblib.load(\"model/XGBoost_voting_ensemble6.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.007622\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  pred = model(torch.FloatTensor(X_val.values).to(\"cuda\"))\n",
    "pred_nn = pred.cpu().detach().numpy()\n",
    "r2 =  r2_score(y_val, pred_nn, sample_weight= w_val)\n",
    "print(f\"R2 score: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [02:45:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.007910\n"
     ]
    }
   ],
   "source": [
    "pred_XGB = XGB_vote_model.predict(X_val)\n",
    "r2 =  r2_score(y_val, pred_XGB, sample_weight= w_val)\n",
    "print(f\"R2 score: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0033342838287353516,\n",
       " 0.0171239972114563,\n",
       " 0.004226744174957275,\n",
       " 0.003619074821472168,\n",
       " 0.016565322875976562,\n",
       " 0.007086396217346191,\n",
       " 0.005833983421325684,\n",
       " 0.005219638347625732,\n",
       " 0.006827950477600098,\n",
       " 0.004177272319793701]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00596308708190918,\n",
       " 0.01482301950454712,\n",
       " 0.005225837230682373,\n",
       " 0.003408968448638916,\n",
       " 0.016702592372894287,\n",
       " 0.007123231887817383,\n",
       " 0.007173597812652588,\n",
       " 0.003072500228881836,\n",
       " 0.007205665111541748,\n",
       " 0.0062503814697265625]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(pred_XGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_r2: 0.008407 , XGB *0.54 + nn0.46\n"
     ]
    }
   ],
   "source": [
    "ratio  = [x/100 for x in range(101)]\n",
    "max_r2 = -5\n",
    "max_i = None\n",
    "for i in ratio:\n",
    "    pred  = pred_XGB*i + pred_nn*(1-i)\n",
    "    r2 =  statistics.mean(cv(pred))\n",
    "    # print(f\"R2 score of XGB * {i} and nn*{1-i}: {r2:.6f}\")\n",
    "    if r2 > max_r2:\n",
    "        max_r2 = r2\n",
    "        max_i = i\n",
    "print(f\"max_r2: {max_r2:.6f} , XGB *{max_i} + nn{1-max_i:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try sth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.008594\n"
     ]
    }
   ],
   "source": [
    "predb = pred_XGB*0.54 + pred_nn*0.46\n",
    "r2 =  r2_score(y_val, predb, sample_weight= w_val)\n",
    "print(f\"R2 score: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble model from other person that share online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [03:00:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\data\\../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb = joblib.load(\"download_model/result.pkl\")\n",
    "xgb_dmodel = xgb[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
